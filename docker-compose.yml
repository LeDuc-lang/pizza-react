  version: "3.9"

  services:
    llm:
      image: ghcr.io/ggerganov/llama.cpp:server
      container_name: qwen_llama
      restart: unless-stopped
      ports:
        - "8080:8080"
      volumes:
        - ./models:/models:ro
      command: >
        -m /models/qwen2.5-7b-instruct-q4_k_m.gguf
        -c 4096
        -t 8
        --host 0.0.0.0
        --port 8080
        --n-predict 256
        --temperature 0.7
      deploy:
        resources:
          limits:
            cpus: "3"
            memory: 12G

    postgres:
      image: postgres:16
      container_name: qwen_postgres
      restart: unless-stopped
      environment:
        POSTGRES_DB: chatbot
        POSTGRES_USER: chatbot
        POSTGRES_PASSWORD: chatbot
      volumes:
        - pgdata:/var/lib/postgresql/data
      ports:
        - "5432:5432"

    backend:
      build: ./backend
      container_name: qwen_backend
      restart: unless-stopped
      ports:
        - "3000:3000"
      environment:
        DATABASE_URL: postgres://chatbot:chatbot@postgres:5432/chatbot
        LLM_URL: http://llm:8080/completion
      depends_on:
        - postgres
        - llm

  volumes:
    pgdata:
